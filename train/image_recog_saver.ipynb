{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0\n",
      "Torchvision Version:  0.5.0a0+0903a9b\n",
      "GeForce GTX 1060\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"/home/mello/dev/enginx/Dataset/\"\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 9\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 32\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 20\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "#Path to the checkpoint directory\n",
    "chk_dir = '/home/mello/.cache/torch/checkpoint/'\n",
    "\n",
    "#Setting the model_history, starting epoch and the i_resume flag as global\n",
    "global model_hist, start_epoch, is_resume\n",
    "model_hist = {'train':[], 'test':[]}\n",
    "start_epoch = 0\n",
    "is_resume = True\n",
    "\n",
    "#Path to the saved checkpoint from where to start the training\n",
    "saved_path = '/home/mello/.cache/torch/checkpoint/saved_squeezenet_195_train_0.90211_test_0.84896_2020-05-06_15-32-32.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summ_image(path, text, n_iter, class_i):\n",
    "    %matplotlib inline\n",
    "    im = plt.imread(path)    \n",
    "    writer.add_image(str(class_i), im.transpose((2,0,1)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False, save_interval = 5):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train','test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels, paths in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        \n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = float(epoch_acc.cpu().numpy())\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            model_hist[phase].append(( start_epoch + epoch, epoch_loss, epoch_acc)) ## continue from saved epoch\n",
    "            \n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "            if phase == 'test':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                \n",
    "            \n",
    "            if epoch%save_interval == 0 and phase == 'test':\n",
    "                save_checkpoint(os.path.join(chk_dir, 'saved'),\n",
    "                                   metric_dict={\n",
    "                                       'epoch': model_hist['train'][-1][0],\n",
    "                                       'type': model_name,\n",
    "                                       'train_acc': model_hist['train'][-1][2],\n",
    "                                       'test_acc': model_hist['test'][-1][2],\n",
    "                                       'model_dict': model_ft.state_dict()\n",
    "                                   })\n",
    "            \n",
    "            if phase == 'test':\n",
    "                writer.add_scalars('data/scalars', {\n",
    "                'train_loss': model_hist['train'][-1][1],\n",
    "                'train_acc': model_hist['train'][-1][2],\n",
    "                'test_acc': model_hist['test'][-1][2]\n",
    "                })                    \n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model, dataloaders, criterion, optimizer, num_epochs=1, is_inception=False, save_interval = 5):\n",
    "    since = time.time()\n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['test']:\n",
    "            model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels, paths in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "                if phase == 'test':\n",
    "                    l = int(preds.cpu().numpy())\n",
    "                    summ_image(paths[0], test_class_dict[l], epoch, test_class_dict[l])\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                time_elapsed = time.time() - since\n",
    "                print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = float(epoch_acc.cpu().numpy())\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            model_hist[phase].append(( start_epoch + epoch, epoch_loss, epoch_acc)) ## continue from saved epoch\n",
    "            \n",
    "            if phase == 'test':\n",
    "                writer.add_scalars('test/scalars', {\n",
    "                'test_acc': model_hist['test'][-1][2]\n",
    "                }) \n",
    "        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG16_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation((-30, 30)),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: ImageFolderWithPaths(os.path.join(data_dir, x, 'Root'), data_transforms[x]) for x in ['train'\n",
    "                                                                                                           , 'test'\n",
    "                                                                                                                ]}\n",
    "# Create training and validation dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=1, shuffle=True, num_workers=4)\n",
    "test_class_dict = {value: key for key, value in testloader.dataset.class_to_idx.items()}\n",
    "dataloaders_dict = {'train': trainloader, 'test': testloader}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolderWithPaths\n",
       "     Number of datapoints: 3800\n",
       "     Root location: /home/mello/dev/enginx/Dataset/train/Root\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                RandomRotation(degrees=(-30, 30), resample=False, expand=False)\n",
       "                RandomVerticalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            ),\n",
       " 'test': Dataset ImageFolderWithPaths\n",
       "     Number of datapoints: 192\n",
       "     Root location: /home/mello/dev/enginx/Dataset/test/Root\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            )}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bittergourd': 0,\n",
       " 'Cabbage': 1,\n",
       " 'Garlic': 2,\n",
       " 'Ginger': 3,\n",
       " 'Onion': 4,\n",
       " 'Pepper': 5,\n",
       " 'Potato': 6,\n",
       " 'Pumpkin': 7,\n",
       " 'Tomato': 8}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = trainloader.dataset.class_to_idx\n",
    "# # uncomment below for writing the dataset classes to a csv file\n",
    "# with open('classes_9.csv', 'w', newline=\"\") as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     for key, value in dummy.items():\n",
    "#         writer.writerow([key, value])\n",
    "dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pat = re.compile(\n",
    "            \"^(\\d{4}-\\d{2}-\\d{2})\\s(\\d{2}:\\d{2}:\\d{2})?\")\n",
    "def get_datetime():  # generates date-time for logging\n",
    "    match = date_pat.search(str(datetime.now()))\n",
    "    date, time = match.group(1), match.group(2)\n",
    "    return date, time\n",
    "\n",
    "def save_checkpoint(path=None, metric_dict=None, mode='train'):\n",
    "\n",
    "    date, time = get_datetime()\n",
    "    time = time.replace(':', '-')\n",
    "    print(date, time)\n",
    "    chk_name = '{}_{}_{}_train_{}_test_{}_{}_{}.pth'.format(\n",
    "        path,\n",
    "        metric_dict['type'],\n",
    "        metric_dict['epoch'],\n",
    "        round(metric_dict['train_acc'], 5),\n",
    "        round(metric_dict['test_acc'], 5),\n",
    "        date,\n",
    "        time\n",
    "    )\n",
    "    torch.save(metric_dict, chk_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load old model / Init new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  195\n",
      "train_acc :  0.9021052631578947\n",
      "test_acc :  0.8489583333333333\n"
     ]
    }
   ],
   "source": [
    "chk_name = saved_path\n",
    "if not os.path.isfile(saved_path):\n",
    "    chk_path = os.path.join(chk_dir, chk_name)\n",
    "else:\n",
    "    chk_path = saved_path\n",
    "    \n",
    "if is_resume:\n",
    "    loaded =  torch.load(chk_path)\n",
    "    [print(x, \": \", loaded[x]) for x in ['epoch', 'train_acc', 'test_acc']];\n",
    "    model_ft.load_state_dict(loaded['model_dict'])\n",
    "    start_epoch = loaded['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "Testing complete in 0m 2s\n",
      "Testing complete in 0m 2s\n",
      "Testing complete in 0m 2s\n",
      "Testing complete in 0m 2s\n",
      "Testing complete in 0m 2s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 3s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 4s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 5s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 6s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 7s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 8s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 9s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 10s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 11s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 12s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 13s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 14s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 15s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 16s\n",
      "Testing complete in 0m 17s\n",
      "Testing complete in 0m 17s\n",
      "Testing complete in 0m 17s\n",
      "Testing complete in 0m 17s\n",
      "Testing complete in 0m 17s\n",
      "Testing complete in 0m 17s\n",
      "Testing complete in 0m 17s\n",
      "Testing complete in 0m 17s\n",
      "test Loss: 0.4187 Acc: 0.8490\n",
      "\n",
      "Testing complete in 0m 17s\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "writer=SummaryWriter()\n",
    "\n",
    "# model_ft, m_hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "model_ft = predict_model(model_ft, dataloaders_dict, criterion, optimizer_ft, is_inception=(model_name==\"inception\"))\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
